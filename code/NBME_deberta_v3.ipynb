{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBME-deberta-v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed8e322115c34d84bdf7e1a6343b31f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe32b0b7d8e5480f9345f7de50b44bfa",
              "IPY_MODEL_ecefada258024ef08f17c6460af04aab",
              "IPY_MODEL_c0add9da83f94d5eb08452724adc6e0c"
            ],
            "layout": "IPY_MODEL_62ea1524033b4af0b39028d585f5d43b"
          }
        },
        "fe32b0b7d8e5480f9345f7de50b44bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_688c296d58e34bca83e79c57a09537b3",
            "placeholder": "​",
            "style": "IPY_MODEL_2bcf214e47194d8797117e73b9e5f41f",
            "value": "100%"
          }
        },
        "ecefada258024ef08f17c6460af04aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d229f359dcf4c5fa092c3536eab8369",
            "max": 42146,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_033ccc23d02d4376a9025379965ff710",
            "value": 42146
          }
        },
        "c0add9da83f94d5eb08452724adc6e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2e5d70f5a2f42d984a754b8c6433e56",
            "placeholder": "​",
            "style": "IPY_MODEL_6f2d967ea4ee4fd890e7974ac0be8fa6",
            "value": " 42146/42146 [00:33&lt;00:00, 1878.87it/s]"
          }
        },
        "62ea1524033b4af0b39028d585f5d43b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688c296d58e34bca83e79c57a09537b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bcf214e47194d8797117e73b9e5f41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d229f359dcf4c5fa092c3536eab8369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "033ccc23d02d4376a9025379965ff710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2e5d70f5a2f42d984a754b8c6433e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f2d967ea4ee4fd890e7974ac0be8fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d001dbc6bba4318af72d9198c42abc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d78b606f99a400ab8f6eb0187f46abe",
              "IPY_MODEL_660a4dbc915b44a1934b0a027c38a875",
              "IPY_MODEL_b431521dee66404da25f5021fe7326a1"
            ],
            "layout": "IPY_MODEL_148f699aa6f9413898bf5fc11c75f4b0"
          }
        },
        "7d78b606f99a400ab8f6eb0187f46abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f00470bf8b184119a9c78703a4dcae36",
            "placeholder": "​",
            "style": "IPY_MODEL_d09a0f0bb3e9477f89c26dd556700ba4",
            "value": "100%"
          }
        },
        "660a4dbc915b44a1934b0a027c38a875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dacadb17ad7e46be8137bee37c3741ec",
            "max": 143,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92b4c45515d543079548070c1b266890",
            "value": 143
          }
        },
        "b431521dee66404da25f5021fe7326a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcebd4992fcd49ebaedd3c76c1be3805",
            "placeholder": "​",
            "style": "IPY_MODEL_adad7d5ecc2c4a4eb3d544f2f23c8018",
            "value": " 143/143 [00:00&lt;00:00, 2349.99it/s]"
          }
        },
        "148f699aa6f9413898bf5fc11c75f4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f00470bf8b184119a9c78703a4dcae36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09a0f0bb3e9477f89c26dd556700ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dacadb17ad7e46be8137bee37c3741ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b4c45515d543079548070c1b266890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcebd4992fcd49ebaedd3c76c1be3805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adad7d5ecc2c4a4eb3d544f2f23c8018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Download Datasets**"
      ],
      "metadata": {
        "id": "glH9tnP4pzRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Download datasets\n",
        "# ====================================================\n",
        "%cd /content\n",
        "%rm -r project\n",
        "%mkdir project\n",
        "%cd project\n",
        "%mkdir input\n",
        "%cd input\n",
        "!wget https://github.com/Ameer-eng/nbme-score-clinical-patient-notes-files/raw/main/nbme-score-clinical-patient-notes.zip\n",
        "!unzip nbme-score-clinical-patient-notes.zip -d nbme-score-clinical-patient-notes\n",
        "!wget https://github.com/Ameer-eng/nbme-score-clinical-patient-notes-files/raw/main/deberta%20v2_3%20fast%20tokenizer.zip\n",
        "!unzip \"deberta v2_3 fast tokenizer.zip\" -d \"deberta-v2-3-fast-tokenizer\"\n",
        "%cd ..\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtfK5qY2pAuO",
        "outputId": "415c7e0a-ecaa-4480-fc18-19e2124e9e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/project\n",
            "/content/project/input\n",
            "--2022-05-01 01:12:05--  https://github.com/Ameer-eng/nbme-score-clinical-patient-notes-files/raw/main/nbme-score-clinical-patient-notes.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Ameer-eng/nbme-score-clinical-patient-notes-files/main/nbme-score-clinical-patient-notes.zip [following]\n",
            "--2022-05-01 01:12:05--  https://raw.githubusercontent.com/Ameer-eng/nbme-score-clinical-patient-notes-files/main/nbme-score-clinical-patient-notes.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10305097 (9.8M) [application/zip]\n",
            "Saving to: ‘nbme-score-clinical-patient-notes.zip’\n",
            "\n",
            "nbme-score-clinical 100%[===================>]   9.83M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-05-01 01:12:05 (221 MB/s) - ‘nbme-score-clinical-patient-notes.zip’ saved [10305097/10305097]\n",
            "\n",
            "Archive:  nbme-score-clinical-patient-notes.zip\n",
            "  inflating: nbme-score-clinical-patient-notes/features.csv  \n",
            "  inflating: nbme-score-clinical-patient-notes/patient_notes.csv  \n",
            "  inflating: nbme-score-clinical-patient-notes/sample_submission.csv  \n",
            "  inflating: nbme-score-clinical-patient-notes/test.csv  \n",
            "  inflating: nbme-score-clinical-patient-notes/train.csv  \n",
            "--2022-05-01 01:12:06--  https://github.com/Ameer-eng/nbme-score-clinical-patient-notes-files/raw/main/deberta%20v2_3%20fast%20tokenizer.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Ameer-eng/nbme-score-clinical-patient-notes-files/main/deberta%20v2_3%20fast%20tokenizer.zip [following]\n",
            "--2022-05-01 01:12:06--  https://raw.githubusercontent.com/Ameer-eng/nbme-score-clinical-patient-notes-files/main/deberta%20v2_3%20fast%20tokenizer.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45640 (45K) [application/zip]\n",
            "Saving to: ‘deberta v2_3 fast tokenizer.zip’\n",
            "\n",
            "deberta v2_3 fast t 100%[===================>]  44.57K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-05-01 01:12:06 (42.2 MB/s) - ‘deberta v2_3 fast tokenizer.zip’ saved [45640/45640]\n",
            "\n",
            "Archive:  deberta v2_3 fast tokenizer.zip\n",
            "  inflating: deberta-v2-3-fast-tokenizer/convert_slow_tokenizer.py  \n",
            "  inflating: deberta-v2-3-fast-tokenizer/deberta__init__.py  \n",
            "  inflating: deberta-v2-3-fast-tokenizer/tokenization_auto.py  \n",
            "  inflating: deberta-v2-3-fast-tokenizer/tokenization_deberta_v2.py  \n",
            "  inflating: deberta-v2-3-fast-tokenizer/tokenization_deberta_v2_fast.py  \n",
            "  inflating: deberta-v2-3-fast-tokenizer/transformers__init__.py  \n",
            "/content/project\n",
            "\u001b[0m\u001b[01;34minput\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hGl6qKn6LT"
      },
      "outputs": [],
      "source": [
        "%mkdir output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi6ifk7SoCKs",
        "outputId": "76d8255b-f52c-48df-897f-ca027543faf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Directory Settings**"
      ],
      "metadata": {
        "id": "OWCTIwVSqNan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Directory settings\n",
        "# ====================================================\n",
        "import os\n",
        "\n",
        "OUTPUT_DIR = './'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "FM90Y_tgoFOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Config**"
      ],
      "metadata": {
        "id": "yeH0RDJWqQ7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# CFG\n",
        "# ====================================================\n",
        "class CFG:\n",
        "    wandb=False\n",
        "    competition='NBME'\n",
        "    _wandb_kernel='nakama'\n",
        "    debug=False\n",
        "    apex=True\n",
        "    print_freq=100\n",
        "    num_workers=4\n",
        "    model=\"microsoft/deberta-v3-base\"\n",
        "    scheduler='cosine' # ['linear', 'cosine']\n",
        "    batch_scheduler=True\n",
        "    num_cycles=0.5\n",
        "    num_warmup_steps=0\n",
        "    epochs=5\n",
        "    encoder_lr=2e-5\n",
        "    decoder_lr=2e-5\n",
        "    min_lr=1e-6\n",
        "    eps=1e-6\n",
        "    betas=(0.9, 0.999)\n",
        "    batch_size=12\n",
        "    fc_dropout=0.2\n",
        "    max_len=512\n",
        "    weight_decay=0.01\n",
        "    gradient_accumulation_steps=1\n",
        "    max_grad_norm=1000\n",
        "    seed=42\n",
        "    n_fold=5\n",
        "    trn_fold=[0, 1, 2, 3, 4]\n",
        "    train=True\n",
        "    \n",
        "if CFG.debug:\n",
        "    CFG.epochs = 2\n",
        "    CFG.trn_fold = [0]"
      ],
      "metadata": {
        "id": "saoEMXBroMEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Library**"
      ],
      "metadata": {
        "id": "mPEB7HtgqxOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import ast\n",
        "import sys\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import pickle\n",
        "import random\n",
        "import joblib\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "#os.system('pip uninstall -y transformers')\n",
        "#os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\n",
        "!pip install transformers\n",
        "!pip install tokenizers\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8246xV4oQ7I",
        "outputId": "7dfa75ef-8624-4dd3-bb78-55053a4d2f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following is necessary to use the fast tokenizer for deberta v2 or v3, which is needed to get character offsets of tokens\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n",
        "\n",
        "input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
        "\n",
        "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
        "conversion_path = transformers_path / convert_file.name\n",
        "\n",
        "if conversion_path.exists():\n",
        "    conversion_path.unlink()\n",
        "\n",
        "shutil.copy(convert_file, transformers_path)\n",
        "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
        "\n",
        "for filename in [\n",
        "    \"tokenization_deberta_v2.py\",\n",
        "    \"tokenization_deberta_v2_fast.py\",\n",
        "    \"deberta__init__.py\",\n",
        "]:\n",
        "    if str(filename).startswith(\"deberta\"):\n",
        "        filepath = deberta_v2_path / str(filename).replace(\"deberta\", \"\")\n",
        "    else:\n",
        "        filepath = deberta_v2_path / filename\n",
        "    if filepath.exists():\n",
        "        filepath.unlink()\n",
        "\n",
        "    shutil.copy(input_dir / filename, filepath)"
      ],
      "metadata": {
        "id": "nkbqK6HTMh9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenizers\n",
        "import transformers\n",
        "\n",
        "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
        "print(f\"transformers.__version__: {transformers.__version__}\")\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "%env TOKENIZERS_PARALLELISM=true\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg7QLny8OcM6",
        "outputId": "36303ddf-d9a9-404c-9ccd-8fb4b12917f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizers.__version__: 0.12.1\n",
            "transformers.__version__: 4.18.0\n",
            "env: TOKENIZERS_PARALLELISM=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the tokenizer\n",
        "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n",
        "tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.model)\n",
        "sequences1 = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"This course is amazing!\",\n",
        "]\n",
        "sequences2 = [\"good\", \"bad\"]\n",
        "batch = tokenizer(\"good tokenizer ather\", add_special_tokens=True,  padding=True, truncation=True, return_offsets_mapping=True)\n",
        "display(batch)\n",
        "tokens = tokenizer.convert_ids_to_tokens(batch[\"input_ids\"])\n",
        "display(tokens)\n",
        "display(batch.sequence_ids())\n",
        "#np.where()[0]\n",
        "np.where(np.array(batch.sequence_ids()) != 0)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "fxq5Z_rPqIir",
        "outputId": "efea7763-8db9-47b0-e3f5-09b0703767d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'input_ids': [1, 397, 10704, 15299, 288, 4441, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 4), (4, 10), (10, 14), (14, 17), (17, 20), (0, 0)]}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['[CLS]', '▁good', '▁token', 'izer', '▁at', 'her', '[SEP]']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[None, 0, 0, 0, 0, 0, None]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions for Scoring**"
      ],
      "metadata": {
        "id": "YnejRNWOwxcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n",
        "\n",
        "def micro_f1(preds, truths):\n",
        "    \"\"\"\n",
        "    Micro f1 on binary arrays.\n",
        "\n",
        "    Args:\n",
        "        preds (list of lists of ints): Predictions.\n",
        "        truths (list of lists of ints): Ground truths.\n",
        "\n",
        "    Returns:\n",
        "        float: f1 score.\n",
        "    \"\"\"\n",
        "    # Micro : aggregating over all instances\n",
        "    preds = np.concatenate(preds)\n",
        "    truths = np.concatenate(truths)\n",
        "    return f1_score(truths, preds)\n",
        "\n",
        "\n",
        "def spans_to_binary(spans, length=None):\n",
        "    \"\"\"\n",
        "    Converts spans to a binary array indicating whether each character is in the span.\n",
        "\n",
        "    Args:\n",
        "        spans (list of lists of two ints): Spans.\n",
        "\n",
        "    Returns:\n",
        "        np array [length]: Binarized spans.\n",
        "    \"\"\"\n",
        "    length = np.max(spans) if length is None else length\n",
        "    binary = np.zeros(length)\n",
        "    for start, end in spans:\n",
        "        binary[start:end] = 1\n",
        "    return binary\n",
        "\n",
        "\n",
        "def span_micro_f1(preds, truths):\n",
        "    \"\"\"\n",
        "    Micro f1 on spans.\n",
        "\n",
        "    Args:\n",
        "        preds (list of lists of two ints): Prediction spans.\n",
        "        truths (list of lists of two ints): Ground truth spans.\n",
        "\n",
        "    Returns:\n",
        "        float: f1 score.\n",
        "    \"\"\"\n",
        "    bin_preds = []\n",
        "    bin_truths = []\n",
        "    for pred, truth in zip(preds, truths):\n",
        "        if not len(pred) and not len(truth):\n",
        "            continue\n",
        "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
        "        bin_preds.append(spans_to_binary(pred, length))\n",
        "        bin_truths.append(spans_to_binary(truth, length))\n",
        "    return micro_f1(bin_preds, bin_truths)"
      ],
      "metadata": {
        "id": "h3_BBWsPwcIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_labels_for_scoring(df):\n",
        "    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n",
        "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
        "    for i in range(len(df)):\n",
        "        lst = df.loc[i, 'location']\n",
        "        if lst:\n",
        "            new_lst = ';'.join(lst)\n",
        "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
        "    # create labels\n",
        "    truths = []\n",
        "    for location_list in df['location_for_create_labels'].values:\n",
        "        truth = []\n",
        "        if len(location_list) > 0:\n",
        "            location = location_list[0]\n",
        "            for loc in [s.split() for s in location.split(';')]:\n",
        "                start, end = int(loc[0]), int(loc[1])\n",
        "                truth.append([start, end])\n",
        "        truths.append(truth)\n",
        "    return truths\n",
        "\n",
        "\n",
        "def get_char_probs(texts, predictions, tokenizer):\n",
        "    results = [np.zeros(len(t)) for t in texts]\n",
        "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
        "        encoded = tokenizer(text, \n",
        "                            add_special_tokens=True,\n",
        "                            return_offsets_mapping=True)\n",
        "        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n",
        "            start = offset_mapping[0]\n",
        "            end = offset_mapping[1]\n",
        "            results[i][start:end] = pred\n",
        "    return results\n",
        "\n",
        "\n",
        "def get_results(char_probs, th=0.5):\n",
        "    results = []\n",
        "    for char_prob in char_probs:\n",
        "        result = np.where(char_prob >= th)[0] + 1\n",
        "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
        "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
        "        result = \";\".join(result)\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "\n",
        "def get_predictions(results):\n",
        "    predictions = []\n",
        "    for result in results:\n",
        "        prediction = []\n",
        "        if result != \"\":\n",
        "            for loc in [s.split() for s in result.split(';')]:\n",
        "                start, end = int(loc[0]), int(loc[1])\n",
        "                prediction.append([start, end])\n",
        "        predictions.append(prediction)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "sFTDPHPyxR6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utils**"
      ],
      "metadata": {
        "id": "mefuHGX-znFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Utils\n",
        "# ====================================================\n",
        "def get_score(y_true, y_pred):\n",
        "    score = span_micro_f1(y_true, y_pred)\n",
        "    return score\n",
        "\n",
        "\n",
        "def get_logger(filename=OUTPUT_DIR+'train'):\n",
        "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "LOGGER = get_logger()\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    \n",
        "seed_everything(seed=42)"
      ],
      "metadata": {
        "id": "63FHL2IJxkgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ],
      "metadata": {
        "id": "Y5xcFIOd0Y8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Data Loading\n",
        "# ====================================================\n",
        "train = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\n",
        "train['annotation'] = train['annotation'].apply(ast.literal_eval)\n",
        "train['location'] = train['location'].apply(ast.literal_eval)\n",
        "features = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\n",
        "patient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\n",
        "\n",
        "print(f\"train.shape: {train.shape}\")\n",
        "display(train.head())\n",
        "print(f\"features.shape: {features.shape}\")\n",
        "display(features.head())\n",
        "print(f\"patient_notes.shape: {patient_notes.shape}\")\n",
        "display(patient_notes.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "Fh0hpOC80XUp",
        "outputId": "be04ff39-57ec-48ec-efe4-35bb5df0d1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.shape: (14300, 6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          id  case_num  pn_num  feature_num                              annotation          location\n",
              "0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]\n",
              "1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]\n",
              "2  00016_002         0      16            2                        [chest pressure]         [203 217]\n",
              "3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]\n",
              "4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06cbadd8-5372-449e-b98c-f4eeb7988e37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>case_num</th>\n",
              "      <th>pn_num</th>\n",
              "      <th>feature_num</th>\n",
              "      <th>annotation</th>\n",
              "      <th>location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00016_000</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>[dad with recent heart attcak]</td>\n",
              "      <td>[696 724]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00016_001</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>[mom with \"thyroid disease]</td>\n",
              "      <td>[668 693]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00016_002</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>[chest pressure]</td>\n",
              "      <td>[203 217]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00016_003</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>[intermittent episodes, episode]</td>\n",
              "      <td>[70 91, 176 183]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00016_004</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>[felt as if he were going to pass out]</td>\n",
              "      <td>[222 258]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06cbadd8-5372-449e-b98c-f4eeb7988e37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06cbadd8-5372-449e-b98c-f4eeb7988e37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06cbadd8-5372-449e-b98c-f4eeb7988e37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.shape: (143, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   feature_num  case_num                                       feature_text\n",
              "0            0         0  Family-history-of-MI-OR-Family-history-of-myoc...\n",
              "1            1         0                 Family-history-of-thyroid-disorder\n",
              "2            2         0                                     Chest-pressure\n",
              "3            3         0                              Intermittent-symptoms\n",
              "4            4         0                                        Lightheaded"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6496433-489b-434d-a823-2b2977525994\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_num</th>\n",
              "      <th>case_num</th>\n",
              "      <th>feature_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Family-history-of-thyroid-disorder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Chest-pressure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Intermittent-symptoms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Lightheaded</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6496433-489b-434d-a823-2b2977525994')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6496433-489b-434d-a823-2b2977525994 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6496433-489b-434d-a823-2b2977525994');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patient_notes.shape: (42146, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   pn_num  case_num                                         pn_history\n",
              "0       0         0  17-year-old male, has come to the student heal...\n",
              "1       1         0  17 yo male with recurrent palpitations for the...\n",
              "2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n",
              "3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
              "4       4         0  17yo male with no pmh here for evaluation of p..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-205663f6-8a2d-4a18-99ea-7d0ace333fa4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pn_num</th>\n",
              "      <th>case_num</th>\n",
              "      <th>pn_history</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17-year-old male, has come to the student heal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>17 yo male with recurrent palpitations for the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Dillon Cleveland is a 17 y.o. male patient wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>a 17 yo m c/o palpitation started 3 mos ago; \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>17yo male with no pmh here for evaluation of p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-205663f6-8a2d-4a18-99ea-7d0ace333fa4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-205663f6-8a2d-4a18-99ea-7d0ace333fa4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-205663f6-8a2d-4a18-99ea-7d0ace333fa4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.merge(features, on=['feature_num', 'case_num'], how='left')\n",
        "train = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
        "display(train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5VQf3smk1AO6",
        "outputId": "452d8bc2-40a4-4a9a-fb5a-6b54bb617916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          id  case_num  pn_num  feature_num                              annotation          location                                       feature_text                                         pn_history\n",
              "0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]  Family-history-of-MI-OR-Family-history-of-myoc...  HPI: 17yo M presents with palpitations. Patien...\n",
              "1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]                 Family-history-of-thyroid-disorder  HPI: 17yo M presents with palpitations. Patien...\n",
              "2  00016_002         0      16            2                        [chest pressure]         [203 217]                                     Chest-pressure  HPI: 17yo M presents with palpitations. Patien...\n",
              "3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]                              Intermittent-symptoms  HPI: 17yo M presents with palpitations. Patien...\n",
              "4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]                                        Lightheaded  HPI: 17yo M presents with palpitations. Patien..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f4cac77-9fca-4485-a4a9-bc5cbbe0de81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>case_num</th>\n",
              "      <th>pn_num</th>\n",
              "      <th>feature_num</th>\n",
              "      <th>annotation</th>\n",
              "      <th>location</th>\n",
              "      <th>feature_text</th>\n",
              "      <th>pn_history</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00016_000</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>[dad with recent heart attcak]</td>\n",
              "      <td>[696 724]</td>\n",
              "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00016_001</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>[mom with \"thyroid disease]</td>\n",
              "      <td>[668 693]</td>\n",
              "      <td>Family-history-of-thyroid-disorder</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00016_002</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>[chest pressure]</td>\n",
              "      <td>[203 217]</td>\n",
              "      <td>Chest-pressure</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00016_003</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>[intermittent episodes, episode]</td>\n",
              "      <td>[70 91, 176 183]</td>\n",
              "      <td>Intermittent-symptoms</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00016_004</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>[felt as if he were going to pass out]</td>\n",
              "      <td>[222 258]</td>\n",
              "      <td>Lightheaded</td>\n",
              "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f4cac77-9fca-4485-a4a9-bc5cbbe0de81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f4cac77-9fca-4485-a4a9-bc5cbbe0de81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f4cac77-9fca-4485-a4a9-bc5cbbe0de81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['annotation_length'] = train['annotation'].apply(len)\n",
        "display(train['annotation_length'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Wjwzrygv1XdC",
        "outputId": "29ce6687-90a8-43d3-ed14-c286a9d50a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1    8181\n",
              "0    4399\n",
              "2    1296\n",
              "3     287\n",
              "4      99\n",
              "5      27\n",
              "6       9\n",
              "7       1\n",
              "8       1\n",
              "Name: annotation_length, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CV Split**"
      ],
      "metadata": {
        "id": "ahto6eVd2R5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# CV split\n",
        "# ====================================================\n",
        "Fold = GroupKFold(n_splits=CFG.n_fold)\n",
        "groups = train['pn_num'].values\n",
        "for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n",
        "    train.loc[val_index, 'fold'] = int(n)\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "display(train.groupby('fold').size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "aD76sB3U2RO5",
        "outputId": "a3612071-ddd1-49bd-b0ef-fc4ef9ab329a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fold\n",
              "0    2860\n",
              "1    2860\n",
              "2    2860\n",
              "3    2860\n",
              "4    2860\n",
              "dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if CFG.debug:\n",
        "    display(train.groupby('fold').size())\n",
        "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
        "    display(train.groupby('fold').size())"
      ],
      "metadata": {
        "id": "0qh6vcCg26CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizer**"
      ],
      "metadata": {
        "id": "1pO54QMA-knj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# tokenizer\n",
        "# ====================================================\n",
        "from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n",
        "tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.model)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
        "CFG.tokenizer = tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8OsyIzV9rDl",
        "outputId": "e2a79b3f-38f9-4896-b893-6a5a8eaa4cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset**"
      ],
      "metadata": {
        "id": "habIFguI-uvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Define max_len\n",
        "# ====================================================\n",
        "for text_col in ['pn_history']:\n",
        "    pn_history_lengths = []\n",
        "    tk0 = tqdm(patient_notes[text_col].fillna(\"\").values, total=len(patient_notes))\n",
        "    for text in tk0:\n",
        "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "        pn_history_lengths.append(length)\n",
        "    LOGGER.info(f'{text_col} max(lengths): {max(pn_history_lengths)}')\n",
        "\n",
        "for text_col in ['feature_text']:\n",
        "    features_lengths = []\n",
        "    tk0 = tqdm(features[text_col].fillna(\"\").values, total=len(features))\n",
        "    for text in tk0:\n",
        "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "        features_lengths.append(length)\n",
        "    LOGGER.info(f'{text_col} max(lengths): {max(features_lengths)}')\n",
        "\n",
        "CFG.max_len = max(pn_history_lengths) + max(features_lengths) + 3 # cls & sep & sep\n",
        "LOGGER.info(f\"max_len: {CFG.max_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "ed8e322115c34d84bdf7e1a6343b31f9",
            "fe32b0b7d8e5480f9345f7de50b44bfa",
            "ecefada258024ef08f17c6460af04aab",
            "c0add9da83f94d5eb08452724adc6e0c",
            "62ea1524033b4af0b39028d585f5d43b",
            "688c296d58e34bca83e79c57a09537b3",
            "2bcf214e47194d8797117e73b9e5f41f",
            "9d229f359dcf4c5fa092c3536eab8369",
            "033ccc23d02d4376a9025379965ff710",
            "a2e5d70f5a2f42d984a754b8c6433e56",
            "6f2d967ea4ee4fd890e7974ac0be8fa6",
            "6d001dbc6bba4318af72d9198c42abc0",
            "7d78b606f99a400ab8f6eb0187f46abe",
            "660a4dbc915b44a1934b0a027c38a875",
            "b431521dee66404da25f5021fe7326a1",
            "148f699aa6f9413898bf5fc11c75f4b0",
            "f00470bf8b184119a9c78703a4dcae36",
            "d09a0f0bb3e9477f89c26dd556700ba4",
            "dacadb17ad7e46be8137bee37c3741ec",
            "92b4c45515d543079548070c1b266890",
            "dcebd4992fcd49ebaedd3c76c1be3805",
            "adad7d5ecc2c4a4eb3d544f2f23c8018"
          ]
        },
        "id": "SCKG9NVR-pTW",
        "outputId": "d6ed9611-b601-4d23-a45c-11c5d4e936fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/42146 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed8e322115c34d84bdf7e1a6343b31f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "pn_history max(lengths): 323\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/143 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d001dbc6bba4318af72d9198c42abc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "feature_text max(lengths): 28\n",
            "max_len: 354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Dataset\n",
        "# ====================================================\n",
        "def prepare_input(cfg, text, feature_text):\n",
        "    \"\"\"\n",
        "    Takes in patient note and feature text pair, and returns tokenized input with values converted into torch tensors.\n",
        "\n",
        "    Args:\n",
        "        cfg (configuration class): configuration.\n",
        "        text (string): patient note.\n",
        "        feature_text (string): feature text.\n",
        "\n",
        "    Returns:\n",
        "       inputs: tokenizer output.\n",
        "    \"\"\"\n",
        "    inputs = cfg.tokenizer(text, feature_text, \n",
        "                           add_special_tokens=True,\n",
        "                           max_length=CFG.max_len,\n",
        "                           padding=\"max_length\",\n",
        "                           return_offsets_mapping=False)\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
        "    return inputs\n",
        "\n",
        "\n",
        "def create_label(cfg, text, annotation_length, location_list):\n",
        "    \"\"\"\n",
        "    Takes in patient note and location list, and returns label tensor with the ith entry being the label of the ith token of the patient note\n",
        "\n",
        "    Args:\n",
        "        cfg (configuration class): configuration.\n",
        "        text (string): patient note.\n",
        "        location_list (list of location strings): locations\n",
        "        annotation_length (int): number of annotations in the location list.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "       labels: tensor of token labels.\n",
        "    \"\"\"\n",
        "    encoded = cfg.tokenizer(text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=CFG.max_len,\n",
        "                            padding=\"max_length\",\n",
        "                            return_offsets_mapping=True)\n",
        "    offset_mapping = encoded['offset_mapping']\n",
        "    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0] # indexes of special tokens\n",
        "    label = np.zeros(len(offset_mapping))\n",
        "    label[ignore_idxes] = -1\n",
        "    if annotation_length != 0:\n",
        "        for location in location_list:\n",
        "            for loc in [s.split() for s in location.split(';')]:\n",
        "              # loc is a start end pair of a span\n",
        "                start_idx = -1\n",
        "                end_idx = -1\n",
        "                start, end = int(loc[0]), int(loc[1])\n",
        "                for idx in range(len(offset_mapping)):\n",
        "                  # Mark all tokens that intersect the location as positive\n",
        "                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
        "                        start_idx = idx - 1\n",
        "                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
        "                        end_idx = idx + 1\n",
        "                if start_idx == -1:\n",
        "                    start_idx = end_idx\n",
        "                if (start_idx != -1) & (end_idx != -1):\n",
        "                    label[start_idx:end_idx] = 1\n",
        "    return torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, cfg, df):\n",
        "        self.cfg = cfg\n",
        "        self.feature_texts = df['feature_text'].values\n",
        "        self.pn_historys = df['pn_history'].values\n",
        "        self.annotation_lengths = df['annotation_length'].values\n",
        "        self.locations = df['location'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.feature_texts)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        inputs = prepare_input(self.cfg, \n",
        "                               self.pn_historys[item], \n",
        "                               self.feature_texts[item])\n",
        "        label = create_label(self.cfg, \n",
        "                             self.pn_historys[item], \n",
        "                             self.annotation_lengths[item], \n",
        "                             self.locations[item])\n",
        "        return inputs, label"
      ],
      "metadata": {
        "id": "az2nXOqdA-eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"k k\".split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMyr7fFRBrRH",
        "outputId": "7a13e53e-edd9-42f7-cd10-cbecdcec764d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['k', 'k']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "-G9Dt13ZYoOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Model\n",
        "# ====================================================\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        if config_path is None:\n",
        "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
        "        else:\n",
        "            self.config = torch.load(config_path)\n",
        "        if pretrained:\n",
        "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
        "        else:\n",
        "            self.model = AutoModel(self.config)\n",
        "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
        "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
        "        self._init_weights(self.fc)\n",
        "        \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "          # Initialize linear head with normally distributed weights, as in deberta\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "        \n",
        "    def feature(self, inputs):\n",
        "        outputs = self.model(**inputs)\n",
        "        last_hidden_states = outputs[0]\n",
        "        return last_hidden_states\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        feature = self.feature(inputs)\n",
        "        output = self.fc(self.fc_dropout(feature))\n",
        "        return output"
      ],
      "metadata": {
        "id": "PmP-KSZ_Yqtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Linear(5, 1)\n",
        "input = torch.tensor([[1.,2.,3.,4.,5.]])\n",
        "output = m(input)\n",
        "display(output)\n",
        "m.weight.data.fill_(0)\n",
        "display(m.weight)\n",
        "m(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "ecOL5zomacsT",
        "outputId": "e7ee46fb-e725-4536-b236-42565340f8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[2.0136]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0., 0., 0., 0., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0902]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**"
      ],
      "metadata": {
        "id": "f7j03-ieEjH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# Helper functions\n",
        "# ====================================================\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "# Trains an epoch and returns the average loss over the epoch.\n",
        "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
        "    losses = AverageMeter()\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    for step, (inputs, labels) in enumerate(train_loader):\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
        "            y_preds = model(inputs)\n",
        "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
        "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        scaler.scale(loss).backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
        "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "            if CFG.batch_scheduler:\n",
        "                scheduler.step()\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
        "            print('Epoch: [{0}][{1}/{2}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  'Grad: {grad_norm:.4f}  '\n",
        "                  'LR: {lr:.8f}  '\n",
        "                  .format(epoch+1, step, len(train_loader), \n",
        "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
        "                          loss=losses,\n",
        "                          grad_norm=grad_norm,\n",
        "                          lr=scheduler.get_lr()[0]))\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
        "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
        "    return losses.avg\n",
        "\n",
        "# returns average loss and predicted probabilities on the validation data\n",
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    losses = AverageMeter()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "    for step, (inputs, labels) in enumerate(valid_loader):\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs)\n",
        "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
        "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.update(loss.item(), batch_size)\n",
        "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
        "        end = time.time()\n",
        "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
        "            print('EVAL: [{0}/{1}] '\n",
        "                  'Elapsed {remain:s} '\n",
        "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
        "                  .format(step, len(valid_loader),\n",
        "                          loss=losses,\n",
        "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
        "    predictions = np.concatenate(preds)\n",
        "    return losses.avg, predictions\n",
        "\n",
        "\n",
        "def inference_fn(test_loader, model, device):\n",
        "    preds = []\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
        "    for inputs in tk0:\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs)\n",
        "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
        "    predictions = np.concatenate(preds)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "FyzVKkAFEcYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# train loop\n",
        "# ====================================================\n",
        "def train_loop(folds, fold):\n",
        "    \n",
        "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
        "\n",
        "    # ====================================================\n",
        "    # loader\n",
        "    # ====================================================\n",
        "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
        "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
        "    valid_texts = valid_folds['pn_history'].values\n",
        "    valid_labels = create_labels_for_scoring(valid_folds)\n",
        "    \n",
        "    train_dataset = TrainDataset(CFG, train_folds)\n",
        "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # model & optimizer\n",
        "    # ====================================================\n",
        "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
        "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
        "    model.to(device)\n",
        "    \n",
        "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_parameters = [\n",
        "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
        "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
        "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        return optimizer_parameters\n",
        "\n",
        "    optimizer_parameters = get_optimizer_params(model,\n",
        "                                                encoder_lr=CFG.encoder_lr, \n",
        "                                                decoder_lr=CFG.decoder_lr,\n",
        "                                                weight_decay=CFG.weight_decay)\n",
        "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
        "    \n",
        "    # ====================================================\n",
        "    # scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
        "        if cfg.scheduler=='linear':\n",
        "            scheduler = get_li\n",
        "            near_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
        "            )\n",
        "        elif cfg.scheduler=='cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
        "            )\n",
        "        return scheduler\n",
        "    \n",
        "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
        "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
        "\n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
        "    \n",
        "    best_score = 0.\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
        "        predictions = predictions.reshape((len(valid_folds), CFG.max_len))\n",
        "        \n",
        "        # scoring\n",
        "        char_probs = get_char_probs(valid_texts, predictions, CFG.tokenizer)\n",
        "        results = get_results(char_probs, th=0.5)\n",
        "        preds = get_predictions(results)\n",
        "        score = get_score(valid_labels, preds)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
        "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
        "        if CFG.wandb:\n",
        "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
        "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
        "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
        "                       f\"[fold{fold}] score\": score})\n",
        "        \n",
        "        if best_score < score:\n",
        "            best_score = score\n",
        "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
        "            torch.save({'model': model.state_dict(),\n",
        "                        'predictions': predictions},\n",
        "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
        "\n",
        "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
        "                             map_location=torch.device('cpu'))['predictions']\n",
        "    valid_folds[[i for i in range(CFG.max_len)]] = predictions\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    return valid_folds"
      ],
      "metadata": {
        "id": "gNWI-ivWGxZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    \n",
        "    def get_result(oof_df):\n",
        "        labels = create_labels_for_scoring(oof_df)\n",
        "        predictions = oof_df[[i for i in range(CFG.max_len)]].values\n",
        "        char_probs = get_char_probs(oof_df['pn_history'].values, predictions, CFG.tokenizer)\n",
        "        results = get_results(char_probs, th=0.5)\n",
        "        preds = get_predictions(results)\n",
        "        score = get_score(labels, preds)\n",
        "        LOGGER.info(f'Score: {score:<.4f}')\n",
        "    \n",
        "    if CFG.train:\n",
        "        oof_df = pd.DataFrame()\n",
        "        for fold in range(CFG.n_fold):\n",
        "            if fold in CFG.trn_fold:\n",
        "                _oof_df = train_loop(train, fold)\n",
        "                oof_df = pd.concat([oof_df, _oof_df])\n",
        "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
        "                get_result(_oof_df)\n",
        "        oof_df = oof_df.reset_index(drop=True)\n",
        "        LOGGER.info(f\"========== CV ==========\")\n",
        "        get_result(oof_df)\n",
        "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
        "        \n",
        "    if CFG.wandb:\n",
        "        wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3r3nHWdG7kT",
        "outputId": "a39abbb1-9917-4d56-bf19-8b567f62af5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "========== fold: 0 training ==========\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/953] Elapsed 0m 1s (remain 19m 44s) Loss: 0.6325(0.6325) Grad: inf  LR: 0.00002000  \n",
            "Epoch: [1][100/953] Elapsed 0m 55s (remain 7m 46s) Loss: 0.0270(0.1007) Grad: 4791.7188  LR: 0.00001998  \n",
            "Epoch: [1][200/953] Elapsed 1m 51s (remain 6m 56s) Loss: 0.0243(0.0667) Grad: 4872.5552  LR: 0.00001991  \n",
            "Epoch: [1][300/953] Elapsed 2m 47s (remain 6m 1s) Loss: 0.0231(0.0534) Grad: 2887.8792  LR: 0.00001980  \n",
            "Epoch: [1][400/953] Elapsed 3m 42s (remain 5m 6s) Loss: 0.0150(0.0459) Grad: 1945.5377  LR: 0.00001965  \n",
            "Epoch: [1][500/953] Elapsed 4m 38s (remain 4m 11s) Loss: 0.0125(0.0409) Grad: 2050.3523  LR: 0.00001946  \n",
            "Epoch: [1][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0215(0.0373) Grad: 3083.3281  LR: 0.00001923  \n",
            "Epoch: [1][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0145(0.0345) Grad: 3096.8455  LR: 0.00001895  \n",
            "Epoch: [1][800/953] Elapsed 7m 26s (remain 1m 24s) Loss: 0.0273(0.0322) Grad: 5382.0942  LR: 0.00001864  \n",
            "Epoch: [1][900/953] Elapsed 8m 22s (remain 0m 29s) Loss: 0.0260(0.0306) Grad: 3915.7664  LR: 0.00001829  \n",
            "Epoch: [1][952/953] Elapsed 8m 51s (remain 0m 0s) Loss: 0.0194(0.0297) Grad: 5671.1011  LR: 0.00001809  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 3m 4s) Loss: 0.0122(0.0122) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0117(0.0138) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0067(0.0159) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0018(0.0149) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0297  avg_val_loss: 0.0149  time: 631s\n",
            "Epoch 1 - Score: 0.8369\n",
            "Epoch 1 - Save Best Score: 0.8369 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2][0/953] Elapsed 0m 1s (remain 20m 31s) Loss: 0.0077(0.0077) Grad: 8760.8018  LR: 0.00001809  \n",
            "Epoch: [2][100/953] Elapsed 0m 58s (remain 8m 17s) Loss: 0.0213(0.0124) Grad: 27182.2617  LR: 0.00001768  \n",
            "Epoch: [2][200/953] Elapsed 1m 56s (remain 7m 15s) Loss: 0.0022(0.0127) Grad: 6075.8027  LR: 0.00001724  \n",
            "Epoch: [2][300/953] Elapsed 2m 54s (remain 6m 17s) Loss: 0.0056(0.0121) Grad: 10123.5254  LR: 0.00001677  \n",
            "Epoch: [2][400/953] Elapsed 3m 51s (remain 5m 18s) Loss: 0.0081(0.0120) Grad: 43455.9531  LR: 0.00001627  \n",
            "Epoch: [2][500/953] Elapsed 4m 49s (remain 4m 20s) Loss: 0.0056(0.0117) Grad: 11445.3262  LR: 0.00001575  \n",
            "Epoch: [2][600/953] Elapsed 5m 46s (remain 3m 23s) Loss: 0.0029(0.0115) Grad: 6487.0635  LR: 0.00001520  \n",
            "Epoch: [2][700/953] Elapsed 6m 44s (remain 2m 25s) Loss: 0.0094(0.0115) Grad: 12834.7314  LR: 0.00001462  \n",
            "Epoch: [2][800/953] Elapsed 7m 41s (remain 1m 27s) Loss: 0.0066(0.0116) Grad: 12947.7129  LR: 0.00001403  \n",
            "Epoch: [2][900/953] Elapsed 8m 39s (remain 0m 29s) Loss: 0.0124(0.0115) Grad: 23502.6602  LR: 0.00001342  \n",
            "Epoch: [2][952/953] Elapsed 9m 9s (remain 0m 0s) Loss: 0.0135(0.0115) Grad: 19447.9746  LR: 0.00001309  \n",
            "EVAL: [0/239] Elapsed 0m 1s (remain 4m 7s) Loss: 0.0088(0.0088) \n",
            "EVAL: [100/239] Elapsed 0m 42s (remain 0m 58s) Loss: 0.0080(0.0130) \n",
            "EVAL: [200/239] Elapsed 1m 24s (remain 0m 15s) Loss: 0.0053(0.0146) \n",
            "EVAL: [238/239] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0023(0.0137) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0115  avg_val_loss: 0.0137  time: 656s\n",
            "Epoch 2 - Score: 0.8573\n",
            "Epoch 2 - Save Best Score: 0.8573 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [3][0/953] Elapsed 0m 1s (remain 16m 2s) Loss: 0.0121(0.0121) Grad: 23047.6602  LR: 0.00001309  \n",
            "Epoch: [3][100/953] Elapsed 0m 58s (remain 8m 16s) Loss: 0.0166(0.0105) Grad: 19886.5117  LR: 0.00001245  \n",
            "Epoch: [3][200/953] Elapsed 1m 56s (remain 7m 15s) Loss: 0.0013(0.0106) Grad: 4658.4321  LR: 0.00001181  \n",
            "Epoch: [3][300/953] Elapsed 2m 53s (remain 6m 16s) Loss: 0.0140(0.0105) Grad: 24620.1523  LR: 0.00001116  \n",
            "Epoch: [3][400/953] Elapsed 3m 51s (remain 5m 18s) Loss: 0.0032(0.0102) Grad: 8419.4219  LR: 0.00001050  \n",
            "Epoch: [3][500/953] Elapsed 4m 48s (remain 4m 20s) Loss: 0.0050(0.0104) Grad: 11215.7051  LR: 0.00000984  \n",
            "Epoch: [3][600/953] Elapsed 5m 46s (remain 3m 22s) Loss: 0.0074(0.0104) Grad: 10711.1377  LR: 0.00000918  \n",
            "Epoch: [3][700/953] Elapsed 6m 43s (remain 2m 25s) Loss: 0.0032(0.0103) Grad: 6767.1377  LR: 0.00000853  \n",
            "Epoch: [3][800/953] Elapsed 7m 41s (remain 1m 27s) Loss: 0.0148(0.0102) Grad: 19685.9844  LR: 0.00000788  \n",
            "Epoch: [3][900/953] Elapsed 8m 38s (remain 0m 29s) Loss: 0.0094(0.0101) Grad: 11670.5537  LR: 0.00000724  \n",
            "Epoch: [3][952/953] Elapsed 9m 8s (remain 0m 0s) Loss: 0.0041(0.0102) Grad: 10367.7012  LR: 0.00000691  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 49s) Loss: 0.0102(0.0102) \n",
            "EVAL: [100/239] Elapsed 0m 42s (remain 0m 57s) Loss: 0.0081(0.0122) \n",
            "EVAL: [200/239] Elapsed 1m 24s (remain 0m 15s) Loss: 0.0043(0.0139) \n",
            "EVAL: [238/239] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0033(0.0130) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0102  avg_val_loss: 0.0130  time: 651s\n",
            "Epoch 3 - Score: 0.8600\n",
            "Epoch 3 - Save Best Score: 0.8600 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [4][0/953] Elapsed 0m 0s (remain 15m 7s) Loss: 0.0039(0.0039) Grad: 6573.1660  LR: 0.00000691  \n",
            "Epoch: [4][100/953] Elapsed 0m 57s (remain 8m 5s) Loss: 0.0067(0.0089) Grad: 18190.6250  LR: 0.00000629  \n",
            "Epoch: [4][200/953] Elapsed 1m 53s (remain 7m 6s) Loss: 0.0158(0.0093) Grad: 31213.8242  LR: 0.00000568  \n",
            "Epoch: [4][300/953] Elapsed 2m 50s (remain 6m 8s) Loss: 0.0053(0.0091) Grad: 10338.5918  LR: 0.00000510  \n",
            "Epoch: [4][400/953] Elapsed 3m 46s (remain 5m 12s) Loss: 0.0047(0.0089) Grad: 18512.3340  LR: 0.00000454  \n",
            "Epoch: [4][500/953] Elapsed 4m 43s (remain 4m 15s) Loss: 0.0055(0.0091) Grad: 16640.1973  LR: 0.00000400  \n",
            "Epoch: [4][600/953] Elapsed 5m 39s (remain 3m 18s) Loss: 0.0053(0.0094) Grad: 14098.4971  LR: 0.00000348  \n",
            "Epoch: [4][700/953] Elapsed 6m 36s (remain 2m 22s) Loss: 0.0100(0.0094) Grad: 20496.7129  LR: 0.00000300  \n",
            "Epoch: [4][800/953] Elapsed 7m 32s (remain 1m 25s) Loss: 0.0147(0.0093) Grad: 21183.2422  LR: 0.00000254  \n",
            "Epoch: [4][900/953] Elapsed 8m 28s (remain 0m 29s) Loss: 0.0106(0.0091) Grad: 27570.9570  LR: 0.00000212  \n",
            "Epoch: [4][952/953] Elapsed 8m 58s (remain 0m 0s) Loss: 0.0144(0.0092) Grad: 29354.1621  LR: 0.00000191  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 49s) Loss: 0.0110(0.0110) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0061(0.0129) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0047(0.0145) \n",
            "EVAL: [238/239] Elapsed 1m 38s (remain 0m 0s) Loss: 0.0017(0.0136) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0092  avg_val_loss: 0.0136  time: 639s\n",
            "Epoch 4 - Score: 0.8615\n",
            "Epoch 4 - Save Best Score: 0.8615 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [5][0/953] Elapsed 0m 1s (remain 15m 52s) Loss: 0.0059(0.0059) Grad: 8278.7158  LR: 0.00000191  \n",
            "Epoch: [5][100/953] Elapsed 0m 56s (remain 7m 59s) Loss: 0.0039(0.0088) Grad: 7482.4946  LR: 0.00000154  \n",
            "Epoch: [5][200/953] Elapsed 1m 52s (remain 7m 0s) Loss: 0.0075(0.0088) Grad: 12922.8965  LR: 0.00000121  \n",
            "Epoch: [5][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0124(0.0087) Grad: 24002.7148  LR: 0.00000091  \n",
            "Epoch: [5][400/953] Elapsed 3m 43s (remain 5m 8s) Loss: 0.0076(0.0088) Grad: 7889.8472  LR: 0.00000066  \n",
            "Epoch: [5][500/953] Elapsed 4m 39s (remain 4m 12s) Loss: 0.0072(0.0087) Grad: 9126.3105  LR: 0.00000044  \n",
            "Epoch: [5][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0094(0.0087) Grad: 16912.9980  LR: 0.00000027  \n",
            "Epoch: [5][700/953] Elapsed 6m 30s (remain 2m 20s) Loss: 0.0051(0.0085) Grad: 9331.1396  LR: 0.00000014  \n",
            "Epoch: [5][800/953] Elapsed 7m 26s (remain 1m 24s) Loss: 0.0231(0.0086) Grad: 31079.0742  LR: 0.00000005  \n",
            "Epoch: [5][900/953] Elapsed 8m 22s (remain 0m 29s) Loss: 0.0070(0.0086) Grad: 17293.6270  LR: 0.00000001  \n",
            "Epoch: [5][952/953] Elapsed 8m 51s (remain 0m 0s) Loss: 0.0084(0.0086) Grad: 19287.0293  LR: 0.00000000  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 33s) Loss: 0.0096(0.0096) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0051(0.0128) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0043(0.0144) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0020(0.0135) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0086  avg_val_loss: 0.0135  time: 636s\n",
            "Epoch 5 - Score: 0.8616\n",
            "Epoch 5 - Save Best Score: 0.8616 Model\n",
            "========== fold: 0 result ==========\n",
            "Score: 0.8616\n",
            "========== fold: 1 training ==========\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/953] Elapsed 0m 0s (remain 14m 58s) Loss: 0.5841(0.5841) Grad: inf  LR: 0.00002000  \n",
            "Epoch: [1][100/953] Elapsed 0m 56s (remain 8m 0s) Loss: 0.0375(0.0868) Grad: 6841.1895  LR: 0.00001998  \n",
            "Epoch: [1][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0323(0.0590) Grad: 7040.6865  LR: 0.00001991  \n",
            "Epoch: [1][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0182(0.0474) Grad: 3285.3870  LR: 0.00001980  \n",
            "Epoch: [1][400/953] Elapsed 3m 43s (remain 5m 8s) Loss: 0.0119(0.0404) Grad: 1299.3373  LR: 0.00001965  \n",
            "Epoch: [1][500/953] Elapsed 4m 39s (remain 4m 12s) Loss: 0.0121(0.0363) Grad: 2545.2024  LR: 0.00001946  \n",
            "Epoch: [1][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0063(0.0333) Grad: 1030.3280  LR: 0.00001923  \n",
            "Epoch: [1][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0323(0.0314) Grad: 3313.3352  LR: 0.00001895  \n",
            "Epoch: [1][800/953] Elapsed 7m 26s (remain 1m 24s) Loss: 0.0239(0.0295) Grad: 6454.3784  LR: 0.00001864  \n",
            "Epoch: [1][900/953] Elapsed 8m 22s (remain 0m 28s) Loss: 0.0158(0.0283) Grad: 2235.6392  LR: 0.00001829  \n",
            "Epoch: [1][952/953] Elapsed 8m 51s (remain 0m 0s) Loss: 0.0404(0.0277) Grad: 3474.2642  LR: 0.00001809  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 35s) Loss: 0.0063(0.0063) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0092(0.0135) \n",
            "EVAL: [200/239] Elapsed 1m 21s (remain 0m 15s) Loss: 0.0164(0.0154) \n",
            "EVAL: [238/239] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0032(0.0147) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0277  avg_val_loss: 0.0147  time: 631s\n",
            "Epoch 1 - Score: 0.8393\n",
            "Epoch 1 - Save Best Score: 0.8393 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2][0/953] Elapsed 0m 0s (remain 15m 46s) Loss: 0.0029(0.0029) Grad: 9095.8730  LR: 0.00001809  \n",
            "Epoch: [2][100/953] Elapsed 0m 57s (remain 8m 1s) Loss: 0.0107(0.0134) Grad: 12974.9873  LR: 0.00001768  \n",
            "Epoch: [2][200/953] Elapsed 1m 52s (remain 7m 2s) Loss: 0.0023(0.0124) Grad: 2814.0134  LR: 0.00001724  \n",
            "Epoch: [2][300/953] Elapsed 2m 48s (remain 6m 5s) Loss: 0.0183(0.0125) Grad: 16201.2900  LR: 0.00001677  \n",
            "Epoch: [2][400/953] Elapsed 3m 44s (remain 5m 9s) Loss: 0.0143(0.0127) Grad: 17413.9746  LR: 0.00001627  \n",
            "Epoch: [2][500/953] Elapsed 4m 40s (remain 4m 13s) Loss: 0.0031(0.0123) Grad: 9750.4824  LR: 0.00001575  \n",
            "Epoch: [2][600/953] Elapsed 5m 36s (remain 3m 16s) Loss: 0.0301(0.0119) Grad: 23988.6602  LR: 0.00001520  \n",
            "Epoch: [2][700/953] Elapsed 6m 32s (remain 2m 21s) Loss: 0.0281(0.0119) Grad: 22561.9453  LR: 0.00001462  \n",
            "Epoch: [2][800/953] Elapsed 7m 28s (remain 1m 25s) Loss: 0.0024(0.0119) Grad: 5011.9727  LR: 0.00001403  \n",
            "Epoch: [2][900/953] Elapsed 8m 23s (remain 0m 29s) Loss: 0.0145(0.0116) Grad: 15844.6768  LR: 0.00001342  \n",
            "Epoch: [2][952/953] Elapsed 8m 52s (remain 0m 0s) Loss: 0.0258(0.0116) Grad: 35178.1367  LR: 0.00001309  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 39s) Loss: 0.0050(0.0050) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0095(0.0118) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0158(0.0142) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0008(0.0135) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0116  avg_val_loss: 0.0135  time: 633s\n",
            "Epoch 2 - Score: 0.8549\n",
            "Epoch 2 - Save Best Score: 0.8549 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [3][0/953] Elapsed 0m 0s (remain 15m 45s) Loss: 0.0077(0.0077) Grad: 15338.0674  LR: 0.00001309  \n",
            "Epoch: [3][100/953] Elapsed 0m 56s (remain 7m 59s) Loss: 0.0045(0.0108) Grad: 11072.2236  LR: 0.00001245  \n",
            "Epoch: [3][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0264(0.0106) Grad: 37687.0977  LR: 0.00001181  \n",
            "Epoch: [3][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0286(0.0104) Grad: 33048.0039  LR: 0.00001116  \n",
            "Epoch: [3][400/953] Elapsed 3m 44s (remain 5m 8s) Loss: 0.0016(0.0101) Grad: 7006.0977  LR: 0.00001050  \n",
            "Epoch: [3][500/953] Elapsed 4m 40s (remain 4m 12s) Loss: 0.0063(0.0101) Grad: 21358.8770  LR: 0.00000984  \n",
            "Epoch: [3][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0170(0.0104) Grad: 27837.7383  LR: 0.00000918  \n",
            "Epoch: [3][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0087(0.0102) Grad: 12556.7598  LR: 0.00000853  \n",
            "Epoch: [3][800/953] Elapsed 7m 27s (remain 1m 24s) Loss: 0.0048(0.0101) Grad: 13335.6045  LR: 0.00000788  \n",
            "Epoch: [3][900/953] Elapsed 8m 23s (remain 0m 29s) Loss: 0.0112(0.0101) Grad: 26997.6562  LR: 0.00000724  \n",
            "Epoch: [3][952/953] Elapsed 8m 52s (remain 0m 0s) Loss: 0.0247(0.0100) Grad: 24558.3262  LR: 0.00000691  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 43s) Loss: 0.0041(0.0041) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0064(0.0120) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0170(0.0146) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0007(0.0138) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0100  avg_val_loss: 0.0138  time: 632s\n",
            "Epoch 3 - Score: 0.8573\n",
            "Epoch 3 - Save Best Score: 0.8573 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [4][0/953] Elapsed 0m 0s (remain 14m 29s) Loss: 0.0089(0.0089) Grad: 29467.1836  LR: 0.00000691  \n",
            "Epoch: [4][100/953] Elapsed 0m 56s (remain 7m 58s) Loss: 0.0064(0.0082) Grad: 15633.3330  LR: 0.00000629  \n",
            "Epoch: [4][200/953] Elapsed 1m 52s (remain 7m 0s) Loss: 0.0033(0.0083) Grad: 12213.8506  LR: 0.00000568  \n",
            "Epoch: [4][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0074(0.0083) Grad: 11497.4668  LR: 0.00000510  \n",
            "Epoch: [4][400/953] Elapsed 3m 43s (remain 5m 7s) Loss: 0.0081(0.0082) Grad: 14440.2646  LR: 0.00000454  \n",
            "Epoch: [4][500/953] Elapsed 4m 39s (remain 4m 12s) Loss: 0.0084(0.0086) Grad: 16385.5371  LR: 0.00000400  \n",
            "Epoch: [4][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0103(0.0087) Grad: 12276.4189  LR: 0.00000348  \n",
            "Epoch: [4][700/953] Elapsed 6m 30s (remain 2m 20s) Loss: 0.0053(0.0088) Grad: 7693.9863  LR: 0.00000300  \n",
            "Epoch: [4][800/953] Elapsed 7m 26s (remain 1m 24s) Loss: 0.0052(0.0089) Grad: 10424.5020  LR: 0.00000254  \n",
            "Epoch: [4][900/953] Elapsed 8m 22s (remain 0m 28s) Loss: 0.0018(0.0090) Grad: 4523.5913  LR: 0.00000212  \n",
            "Epoch: [4][952/953] Elapsed 8m 51s (remain 0m 0s) Loss: 0.0105(0.0090) Grad: 17312.1230  LR: 0.00000191  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 53s) Loss: 0.0044(0.0044) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0082(0.0114) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0167(0.0141) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0007(0.0134) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0090  avg_val_loss: 0.0134  time: 631s\n",
            "Epoch 4 - Score: 0.8633\n",
            "Epoch 4 - Save Best Score: 0.8633 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [5][0/953] Elapsed 0m 1s (remain 16m 7s) Loss: 0.0026(0.0026) Grad: 6648.4517  LR: 0.00000191  \n",
            "Epoch: [5][100/953] Elapsed 0m 56s (remain 8m 0s) Loss: 0.0112(0.0085) Grad: 23956.0918  LR: 0.00000154  \n",
            "Epoch: [5][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0102(0.0087) Grad: 14938.9307  LR: 0.00000121  \n",
            "Epoch: [5][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0018(0.0083) Grad: 3669.2937  LR: 0.00000091  \n",
            "Epoch: [5][400/953] Elapsed 3m 44s (remain 5m 8s) Loss: 0.0129(0.0086) Grad: 18900.4824  LR: 0.00000066  \n",
            "Epoch: [5][500/953] Elapsed 4m 40s (remain 4m 12s) Loss: 0.0072(0.0085) Grad: 15878.4443  LR: 0.00000044  \n",
            "Epoch: [5][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0031(0.0084) Grad: 12752.5654  LR: 0.00000027  \n",
            "Epoch: [5][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0023(0.0084) Grad: 6125.4668  LR: 0.00000014  \n",
            "Epoch: [5][800/953] Elapsed 7m 27s (remain 1m 24s) Loss: 0.0141(0.0085) Grad: 23793.3945  LR: 0.00000005  \n",
            "Epoch: [5][900/953] Elapsed 8m 23s (remain 0m 29s) Loss: 0.0016(0.0083) Grad: 5126.3589  LR: 0.00000001  \n",
            "Epoch: [5][952/953] Elapsed 8m 52s (remain 0m 0s) Loss: 0.0223(0.0084) Grad: 27624.6816  LR: 0.00000000  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 45s) Loss: 0.0044(0.0044) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0096(0.0117) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0175(0.0144) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0006(0.0136) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0084  avg_val_loss: 0.0136  time: 632s\n",
            "Epoch 5 - Score: 0.8643\n",
            "Epoch 5 - Save Best Score: 0.8643 Model\n",
            "========== fold: 1 result ==========\n",
            "Score: 0.8643\n",
            "========== fold: 2 training ==========\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/953] Elapsed 0m 0s (remain 15m 11s) Loss: 0.2833(0.2833) Grad: inf  LR: 0.00002000  \n",
            "Epoch: [1][100/953] Elapsed 0m 57s (remain 8m 0s) Loss: 0.0384(0.0650) Grad: 7271.9932  LR: 0.00001998  \n",
            "Epoch: [1][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0429(0.0484) Grad: 17328.7383  LR: 0.00001991  \n",
            "Epoch: [1][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0217(0.0407) Grad: 7726.3184  LR: 0.00001980  \n",
            "Epoch: [1][400/953] Elapsed 3m 44s (remain 5m 8s) Loss: 0.0316(0.0355) Grad: 11681.3701  LR: 0.00001965  \n",
            "Epoch: [1][500/953] Elapsed 4m 39s (remain 4m 12s) Loss: 0.0088(0.0325) Grad: 2545.7996  LR: 0.00001946  \n",
            "Epoch: [1][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0169(0.0301) Grad: 4386.5894  LR: 0.00001923  \n",
            "Epoch: [1][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0161(0.0285) Grad: 8347.5371  LR: 0.00001895  \n",
            "Epoch: [1][800/953] Elapsed 7m 27s (remain 1m 24s) Loss: 0.0102(0.0269) Grad: 4161.8271  LR: 0.00001864  \n",
            "Epoch: [1][900/953] Elapsed 8m 23s (remain 0m 29s) Loss: 0.0090(0.0256) Grad: 5611.7212  LR: 0.00001829  \n",
            "Epoch: [1][952/953] Elapsed 8m 52s (remain 0m 0s) Loss: 0.0587(0.0251) Grad: 17140.8945  LR: 0.00001809  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 49s) Loss: 0.0116(0.0116) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0137(0.0171) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0078(0.0174) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0006(0.0159) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0251  avg_val_loss: 0.0159  time: 632s\n",
            "Epoch 1 - Score: 0.8119\n",
            "Epoch 1 - Save Best Score: 0.8119 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2][0/953] Elapsed 0m 1s (remain 17m 22s) Loss: 0.0534(0.0534) Grad: 86812.6328  LR: 0.00001809  \n",
            "Epoch: [2][100/953] Elapsed 0m 57s (remain 8m 1s) Loss: 0.0025(0.0130) Grad: 5722.5005  LR: 0.00001768  \n",
            "Epoch: [2][200/953] Elapsed 1m 53s (remain 7m 3s) Loss: 0.0079(0.0128) Grad: 37133.4727  LR: 0.00001724  \n",
            "Epoch: [2][300/953] Elapsed 2m 49s (remain 6m 6s) Loss: 0.0163(0.0123) Grad: 18501.6465  LR: 0.00001677  \n",
            "Epoch: [2][400/953] Elapsed 3m 45s (remain 5m 9s) Loss: 0.0057(0.0123) Grad: 20124.3203  LR: 0.00001627  \n",
            "Epoch: [2][500/953] Elapsed 4m 41s (remain 4m 13s) Loss: 0.0098(0.0122) Grad: 16600.7500  LR: 0.00001575  \n",
            "Epoch: [2][600/953] Elapsed 5m 37s (remain 3m 17s) Loss: 0.0084(0.0122) Grad: 12996.7139  LR: 0.00001520  \n",
            "Epoch: [2][700/953] Elapsed 6m 33s (remain 2m 21s) Loss: 0.0159(0.0122) Grad: 24887.1367  LR: 0.00001462  \n",
            "Epoch: [2][800/953] Elapsed 7m 29s (remain 1m 25s) Loss: 0.0132(0.0120) Grad: 23411.2344  LR: 0.00001403  \n",
            "Epoch: [2][900/953] Elapsed 8m 25s (remain 0m 29s) Loss: 0.0091(0.0119) Grad: 14800.1855  LR: 0.00001342  \n",
            "Epoch: [2][952/953] Elapsed 8m 54s (remain 0m 0s) Loss: 0.0047(0.0118) Grad: 6482.9355  LR: 0.00001309  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 40s) Loss: 0.0087(0.0087) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0082(0.0134) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0045(0.0142) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0003(0.0131) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0118  avg_val_loss: 0.0131  time: 635s\n",
            "Epoch 2 - Score: 0.8566\n",
            "Epoch 2 - Save Best Score: 0.8566 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [3][0/953] Elapsed 0m 1s (remain 16m 19s) Loss: 0.0049(0.0049) Grad: 11561.6523  LR: 0.00001309  \n",
            "Epoch: [3][100/953] Elapsed 0m 56s (remain 7m 59s) Loss: 0.0101(0.0093) Grad: 19466.3164  LR: 0.00001245  \n",
            "Epoch: [3][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0023(0.0097) Grad: 6262.3706  LR: 0.00001181  \n",
            "Epoch: [3][300/953] Elapsed 2m 48s (remain 6m 5s) Loss: 0.0085(0.0097) Grad: 21641.7324  LR: 0.00001116  \n",
            "Epoch: [3][400/953] Elapsed 3m 44s (remain 5m 9s) Loss: 0.0145(0.0102) Grad: 13644.6719  LR: 0.00001050  \n",
            "Epoch: [3][500/953] Elapsed 4m 40s (remain 4m 12s) Loss: 0.0012(0.0101) Grad: 3582.8213  LR: 0.00000984  \n",
            "Epoch: [3][600/953] Elapsed 5m 36s (remain 3m 16s) Loss: 0.0079(0.0099) Grad: 20627.0684  LR: 0.00000918  \n",
            "Epoch: [3][700/953] Elapsed 6m 32s (remain 2m 20s) Loss: 0.0209(0.0100) Grad: 38610.3359  LR: 0.00000853  \n",
            "Epoch: [3][800/953] Elapsed 7m 28s (remain 1m 25s) Loss: 0.0239(0.0101) Grad: 36272.8672  LR: 0.00000788  \n",
            "Epoch: [3][900/953] Elapsed 8m 24s (remain 0m 29s) Loss: 0.0075(0.0101) Grad: 22834.2852  LR: 0.00000724  \n",
            "Epoch: [3][952/953] Elapsed 8m 53s (remain 0m 0s) Loss: 0.0049(0.0100) Grad: 17197.8770  LR: 0.00000691  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 3m 1s) Loss: 0.0084(0.0084) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0065(0.0142) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0037(0.0147) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0002(0.0135) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0100  avg_val_loss: 0.0135  time: 633s\n",
            "Epoch 3 - Score: 0.8613\n",
            "Epoch 3 - Save Best Score: 0.8613 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [4][0/953] Elapsed 0m 1s (remain 16m 39s) Loss: 0.0011(0.0011) Grad: 8988.3779  LR: 0.00000691  \n",
            "Epoch: [4][100/953] Elapsed 0m 56s (remain 7m 59s) Loss: 0.0246(0.0091) Grad: 40938.5703  LR: 0.00000629  \n",
            "Epoch: [4][200/953] Elapsed 1m 52s (remain 7m 2s) Loss: 0.0045(0.0094) Grad: 42879.4883  LR: 0.00000568  \n",
            "Epoch: [4][300/953] Elapsed 2m 48s (remain 6m 5s) Loss: 0.0096(0.0090) Grad: 31326.3594  LR: 0.00000510  \n",
            "Epoch: [4][400/953] Elapsed 3m 44s (remain 5m 9s) Loss: 0.0075(0.0089) Grad: 17543.1270  LR: 0.00000454  \n",
            "Epoch: [4][500/953] Elapsed 4m 40s (remain 4m 13s) Loss: 0.0241(0.0086) Grad: 18296.5938  LR: 0.00000400  \n",
            "Epoch: [4][600/953] Elapsed 5m 36s (remain 3m 17s) Loss: 0.0057(0.0085) Grad: 8752.5078  LR: 0.00000348  \n",
            "Epoch: [4][700/953] Elapsed 6m 32s (remain 2m 21s) Loss: 0.0216(0.0086) Grad: 17018.3281  LR: 0.00000300  \n",
            "Epoch: [4][800/953] Elapsed 7m 28s (remain 1m 25s) Loss: 0.0013(0.0086) Grad: 3989.7292  LR: 0.00000254  \n",
            "Epoch: [4][900/953] Elapsed 8m 24s (remain 0m 29s) Loss: 0.0109(0.0087) Grad: 26326.9102  LR: 0.00000212  \n",
            "Epoch: [4][952/953] Elapsed 8m 53s (remain 0m 0s) Loss: 0.0031(0.0086) Grad: 6486.3833  LR: 0.00000191  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 53s) Loss: 0.0091(0.0091) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0070(0.0138) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0047(0.0144) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0002(0.0131) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0086  avg_val_loss: 0.0131  time: 634s\n",
            "Epoch 4 - Score: 0.8661\n",
            "Epoch 4 - Save Best Score: 0.8661 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [5][0/953] Elapsed 0m 1s (remain 16m 20s) Loss: 0.0083(0.0083) Grad: 9512.6270  LR: 0.00000191  \n",
            "Epoch: [5][100/953] Elapsed 0m 56s (remain 7m 58s) Loss: 0.0214(0.0086) Grad: 62217.8086  LR: 0.00000154  \n",
            "Epoch: [5][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0089(0.0086) Grad: 22191.6621  LR: 0.00000121  \n",
            "Epoch: [5][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0078(0.0083) Grad: 16323.6260  LR: 0.00000091  \n",
            "Epoch: [5][400/953] Elapsed 3m 44s (remain 5m 8s) Loss: 0.0031(0.0085) Grad: 15154.5771  LR: 0.00000066  \n",
            "Epoch: [5][500/953] Elapsed 4m 40s (remain 4m 12s) Loss: 0.0057(0.0083) Grad: 8248.5479  LR: 0.00000044  \n",
            "Epoch: [5][600/953] Elapsed 5m 36s (remain 3m 16s) Loss: 0.0033(0.0081) Grad: 10812.9766  LR: 0.00000027  \n",
            "Epoch: [5][700/953] Elapsed 6m 32s (remain 2m 20s) Loss: 0.0098(0.0079) Grad: 21135.4238  LR: 0.00000014  \n",
            "Epoch: [5][800/953] Elapsed 7m 27s (remain 1m 24s) Loss: 0.0089(0.0079) Grad: 36131.4453  LR: 0.00000005  \n",
            "Epoch: [5][900/953] Elapsed 8m 23s (remain 0m 29s) Loss: 0.0013(0.0078) Grad: 12175.6387  LR: 0.00000001  \n",
            "Epoch: [5][952/953] Elapsed 8m 52s (remain 0m 0s) Loss: 0.0017(0.0078) Grad: 5168.5269  LR: 0.00000000  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 57s) Loss: 0.0094(0.0094) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0073(0.0142) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0041(0.0147) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0002(0.0133) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0078  avg_val_loss: 0.0133  time: 633s\n",
            "Epoch 5 - Score: 0.8661\n",
            "========== fold: 2 result ==========\n",
            "Score: 0.8661\n",
            "========== fold: 3 training ==========\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/953] Elapsed 0m 0s (remain 14m 41s) Loss: 1.2440(1.2440) Grad: inf  LR: 0.00002000  \n",
            "Epoch: [1][100/953] Elapsed 0m 56s (remain 7m 59s) Loss: 0.0488(0.1514) Grad: 1116.7002  LR: 0.00001998  \n",
            "Epoch: [1][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0250(0.0953) Grad: 1316.1116  LR: 0.00001991  \n",
            "Epoch: [1][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0203(0.0724) Grad: 2352.5986  LR: 0.00001980  \n",
            "Epoch: [1][400/953] Elapsed 3m 44s (remain 5m 8s) Loss: 0.0275(0.0595) Grad: 1272.9961  LR: 0.00001965  \n",
            "Epoch: [1][500/953] Elapsed 4m 40s (remain 4m 12s) Loss: 0.0239(0.0515) Grad: 1240.9419  LR: 0.00001946  \n",
            "Epoch: [1][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0303(0.0460) Grad: 687.4151  LR: 0.00001923  \n",
            "Epoch: [1][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0136(0.0418) Grad: 1389.7552  LR: 0.00001895  \n",
            "Epoch: [1][800/953] Elapsed 7m 27s (remain 1m 24s) Loss: 0.0234(0.0388) Grad: 1123.1578  LR: 0.00001864  \n",
            "Epoch: [1][900/953] Elapsed 8m 22s (remain 0m 29s) Loss: 0.0703(0.0365) Grad: 5954.8613  LR: 0.00001829  \n",
            "Epoch: [1][952/953] Elapsed 8m 51s (remain 0m 0s) Loss: 0.0152(0.0353) Grad: 1548.8789  LR: 0.00001809  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 52s) Loss: 0.0176(0.0176) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0204(0.0155) \n",
            "EVAL: [200/239] Elapsed 1m 21s (remain 0m 15s) Loss: 0.0134(0.0173) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0005(0.0158) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0353  avg_val_loss: 0.0158  time: 632s\n",
            "Epoch 1 - Score: 0.8296\n",
            "Epoch 1 - Save Best Score: 0.8296 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2][0/953] Elapsed 0m 1s (remain 16m 41s) Loss: 0.0263(0.0263) Grad: 17257.6738  LR: 0.00001809  \n",
            "Epoch: [2][100/953] Elapsed 0m 57s (remain 8m 1s) Loss: 0.0013(0.0140) Grad: 3104.8445  LR: 0.00001768  \n",
            "Epoch: [2][200/953] Elapsed 1m 52s (remain 7m 2s) Loss: 0.0019(0.0127) Grad: 4048.4014  LR: 0.00001724  \n",
            "Epoch: [2][300/953] Elapsed 2m 48s (remain 6m 5s) Loss: 0.0038(0.0128) Grad: 11712.8760  LR: 0.00001677  \n",
            "Epoch: [2][400/953] Elapsed 3m 44s (remain 5m 9s) Loss: 0.0364(0.0127) Grad: 16240.8086  LR: 0.00001627  \n",
            "Epoch: [2][500/953] Elapsed 4m 40s (remain 4m 13s) Loss: 0.0074(0.0122) Grad: 10888.9658  LR: 0.00001575  \n",
            "Epoch: [2][600/953] Elapsed 5m 36s (remain 3m 17s) Loss: 0.0171(0.0120) Grad: 24338.3691  LR: 0.00001520  \n",
            "Epoch: [2][700/953] Elapsed 6m 32s (remain 2m 21s) Loss: 0.0056(0.0118) Grad: 13329.0801  LR: 0.00001462  \n",
            "Epoch: [2][800/953] Elapsed 7m 28s (remain 1m 25s) Loss: 0.0022(0.0119) Grad: 7986.5464  LR: 0.00001403  \n",
            "Epoch: [2][900/953] Elapsed 8m 24s (remain 0m 29s) Loss: 0.0229(0.0117) Grad: 27289.9473  LR: 0.00001342  \n",
            "Epoch: [2][952/953] Elapsed 8m 53s (remain 0m 0s) Loss: 0.0037(0.0116) Grad: 6118.8916  LR: 0.00001309  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 45s) Loss: 0.0102(0.0102) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0159(0.0133) \n",
            "EVAL: [200/239] Elapsed 1m 21s (remain 0m 15s) Loss: 0.0109(0.0153) \n",
            "EVAL: [238/239] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0002(0.0140) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0116  avg_val_loss: 0.0140  time: 633s\n",
            "Epoch 2 - Score: 0.8563\n",
            "Epoch 2 - Save Best Score: 0.8563 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [3][0/953] Elapsed 0m 0s (remain 15m 41s) Loss: 0.0152(0.0152) Grad: 22719.5605  LR: 0.00001309  \n",
            "Epoch: [3][100/953] Elapsed 0m 56s (remain 8m 0s) Loss: 0.0115(0.0112) Grad: 17065.5156  LR: 0.00001245  \n",
            "Epoch: [3][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0056(0.0114) Grad: 11509.0684  LR: 0.00001181  \n",
            "Epoch: [3][300/953] Elapsed 2m 48s (remain 6m 5s) Loss: 0.0122(0.0108) Grad: 18811.7109  LR: 0.00001116  \n",
            "Epoch: [3][400/953] Elapsed 3m 44s (remain 5m 8s) Loss: 0.0388(0.0108) Grad: 30578.5820  LR: 0.00001050  \n",
            "Epoch: [3][500/953] Elapsed 4m 40s (remain 4m 12s) Loss: 0.0097(0.0105) Grad: 15086.7539  LR: 0.00000984  \n",
            "Epoch: [3][600/953] Elapsed 5m 36s (remain 3m 16s) Loss: 0.0253(0.0104) Grad: 33156.6523  LR: 0.00000918  \n",
            "Epoch: [3][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0021(0.0104) Grad: 3744.9819  LR: 0.00000853  \n",
            "Epoch: [3][800/953] Elapsed 7m 27s (remain 1m 24s) Loss: 0.0086(0.0104) Grad: 11628.2197  LR: 0.00000788  \n",
            "Epoch: [3][900/953] Elapsed 8m 23s (remain 0m 29s) Loss: 0.0136(0.0104) Grad: 15796.2646  LR: 0.00000724  \n",
            "Epoch: [3][952/953] Elapsed 8m 52s (remain 0m 0s) Loss: 0.0341(0.0104) Grad: 21637.4727  LR: 0.00000691  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 48s) Loss: 0.0099(0.0099) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0169(0.0127) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0103(0.0149) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0002(0.0135) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0104  avg_val_loss: 0.0135  time: 632s\n",
            "Epoch 3 - Score: 0.8616\n",
            "Epoch 3 - Save Best Score: 0.8616 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [4][0/953] Elapsed 0m 0s (remain 15m 48s) Loss: 0.0035(0.0035) Grad: 9704.5479  LR: 0.00000691  \n",
            "Epoch: [4][100/953] Elapsed 0m 56s (remain 7m 59s) Loss: 0.0044(0.0098) Grad: 6691.7886  LR: 0.00000629  \n",
            "Epoch: [4][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0044(0.0091) Grad: 4136.0239  LR: 0.00000568  \n",
            "Epoch: [4][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0114(0.0096) Grad: 17939.2910  LR: 0.00000510  \n",
            "Epoch: [4][400/953] Elapsed 3m 44s (remain 5m 8s) Loss: 0.0034(0.0094) Grad: 15111.5703  LR: 0.00000454  \n",
            "Epoch: [4][500/953] Elapsed 4m 39s (remain 4m 12s) Loss: 0.0065(0.0094) Grad: 7679.8135  LR: 0.00000400  \n",
            "Epoch: [4][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0023(0.0096) Grad: 5168.5215  LR: 0.00000348  \n",
            "Epoch: [4][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0033(0.0100) Grad: 5715.0312  LR: 0.00000300  \n",
            "Epoch: [4][800/953] Elapsed 7m 27s (remain 1m 24s) Loss: 0.0086(0.0099) Grad: 18823.5820  LR: 0.00000254  \n",
            "Epoch: [4][900/953] Elapsed 8m 22s (remain 0m 29s) Loss: 0.0065(0.0099) Grad: 13504.3701  LR: 0.00000212  \n",
            "Epoch: [4][952/953] Elapsed 8m 51s (remain 0m 0s) Loss: 0.0083(0.0099) Grad: 15683.6289  LR: 0.00000191  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 47s) Loss: 0.0127(0.0127) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0190(0.0130) \n",
            "EVAL: [200/239] Elapsed 1m 21s (remain 0m 15s) Loss: 0.0103(0.0152) \n",
            "EVAL: [238/239] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0001(0.0139) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0099  avg_val_loss: 0.0139  time: 631s\n",
            "Epoch 4 - Score: 0.8604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [5][0/953] Elapsed 0m 0s (remain 15m 0s) Loss: 0.0024(0.0024) Grad: 6767.1919  LR: 0.00000191  \n",
            "Epoch: [5][100/953] Elapsed 0m 56s (remain 7m 59s) Loss: 0.0054(0.0087) Grad: 14920.7412  LR: 0.00000154  \n",
            "Epoch: [5][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0135(0.0087) Grad: 24867.8770  LR: 0.00000121  \n",
            "Epoch: [5][300/953] Elapsed 2m 48s (remain 6m 5s) Loss: 0.0077(0.0087) Grad: 10293.4873  LR: 0.00000091  \n",
            "Epoch: [5][400/953] Elapsed 3m 44s (remain 5m 9s) Loss: 0.0114(0.0088) Grad: 13030.3506  LR: 0.00000066  \n",
            "Epoch: [5][500/953] Elapsed 4m 40s (remain 4m 13s) Loss: 0.0027(0.0090) Grad: 5702.5054  LR: 0.00000044  \n",
            "Epoch: [5][600/953] Elapsed 5m 36s (remain 3m 16s) Loss: 0.0045(0.0093) Grad: 11720.5244  LR: 0.00000027  \n",
            "Epoch: [5][700/953] Elapsed 6m 32s (remain 2m 20s) Loss: 0.0051(0.0095) Grad: 9323.4893  LR: 0.00000014  \n",
            "Epoch: [5][800/953] Elapsed 7m 27s (remain 1m 25s) Loss: 0.0027(0.0094) Grad: 7416.7617  LR: 0.00000005  \n",
            "Epoch: [5][900/953] Elapsed 8m 23s (remain 0m 29s) Loss: 0.0072(0.0094) Grad: 22182.9590  LR: 0.00000001  \n",
            "Epoch: [5][952/953] Elapsed 8m 52s (remain 0m 0s) Loss: 0.0092(0.0093) Grad: 21689.2402  LR: 0.00000000  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 37s) Loss: 0.0119(0.0119) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0189(0.0130) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0101(0.0153) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0001(0.0140) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0093  avg_val_loss: 0.0140  time: 633s\n",
            "Epoch 5 - Score: 0.8611\n",
            "========== fold: 3 result ==========\n",
            "Score: 0.8616\n",
            "========== fold: 4 training ==========\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1][0/953] Elapsed 0m 0s (remain 14m 54s) Loss: 0.7371(0.7371) Grad: inf  LR: 0.00002000  \n",
            "Epoch: [1][100/953] Elapsed 0m 56s (remain 8m 0s) Loss: 0.0239(0.1021) Grad: 2168.4497  LR: 0.00001998  \n",
            "Epoch: [1][200/953] Elapsed 1m 52s (remain 7m 1s) Loss: 0.0164(0.0665) Grad: 4387.1943  LR: 0.00001991  \n",
            "Epoch: [1][300/953] Elapsed 2m 48s (remain 6m 4s) Loss: 0.0107(0.0526) Grad: 2305.9619  LR: 0.00001980  \n",
            "Epoch: [1][400/953] Elapsed 3m 44s (remain 5m 8s) Loss: 0.0095(0.0455) Grad: 2289.4265  LR: 0.00001965  \n",
            "Epoch: [1][500/953] Elapsed 4m 40s (remain 4m 12s) Loss: 0.0116(0.0405) Grad: 2245.0413  LR: 0.00001946  \n",
            "Epoch: [1][600/953] Elapsed 5m 35s (remain 3m 16s) Loss: 0.0299(0.0371) Grad: 2730.5737  LR: 0.00001923  \n",
            "Epoch: [1][700/953] Elapsed 6m 31s (remain 2m 20s) Loss: 0.0043(0.0344) Grad: 863.8657  LR: 0.00001895  \n",
            "Epoch: [1][800/953] Elapsed 7m 27s (remain 1m 24s) Loss: 0.0304(0.0322) Grad: 5839.6255  LR: 0.00001864  \n",
            "Epoch: [1][900/953] Elapsed 8m 23s (remain 0m 29s) Loss: 0.0291(0.0305) Grad: 5310.3931  LR: 0.00001829  \n",
            "Epoch: [1][952/953] Elapsed 8m 52s (remain 0m 0s) Loss: 0.0112(0.0296) Grad: 2205.2041  LR: 0.00001809  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 52s) Loss: 0.0096(0.0096) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0073(0.0133) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0036(0.0150) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0078(0.0140) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - avg_train_loss: 0.0296  avg_val_loss: 0.0140  time: 632s\n",
            "Epoch 1 - Score: 0.8441\n",
            "Epoch 1 - Save Best Score: 0.8441 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [2][0/953] Elapsed 0m 1s (remain 15m 57s) Loss: 0.0026(0.0026) Grad: 5493.4834  LR: 0.00001809  \n",
            "Epoch: [2][100/953] Elapsed 0m 57s (remain 8m 1s) Loss: 0.0230(0.0111) Grad: 32209.4023  LR: 0.00001768  \n",
            "Epoch: [2][200/953] Elapsed 1m 53s (remain 7m 2s) Loss: 0.0072(0.0111) Grad: 16271.6533  LR: 0.00001724  \n",
            "Epoch: [2][300/953] Elapsed 2m 48s (remain 6m 5s) Loss: 0.0066(0.0114) Grad: 10108.2090  LR: 0.00001677  \n",
            "Epoch: [2][400/953] Elapsed 3m 44s (remain 5m 9s) Loss: 0.0125(0.0111) Grad: 35264.3984  LR: 0.00001627  \n",
            "Epoch: [2][500/953] Elapsed 4m 40s (remain 4m 13s) Loss: 0.0052(0.0112) Grad: 5816.7246  LR: 0.00001575  \n",
            "Epoch: [2][600/953] Elapsed 5m 36s (remain 3m 17s) Loss: 0.0074(0.0113) Grad: 9804.8086  LR: 0.00001520  \n",
            "Epoch: [2][700/953] Elapsed 6m 33s (remain 2m 21s) Loss: 0.0068(0.0113) Grad: 7752.7227  LR: 0.00001462  \n",
            "Epoch: [2][800/953] Elapsed 7m 29s (remain 1m 25s) Loss: 0.0049(0.0113) Grad: 10019.1670  LR: 0.00001403  \n",
            "Epoch: [2][900/953] Elapsed 8m 25s (remain 0m 29s) Loss: 0.0269(0.0114) Grad: 37970.9531  LR: 0.00001342  \n",
            "Epoch: [2][952/953] Elapsed 8m 54s (remain 0m 0s) Loss: 0.0093(0.0115) Grad: 11216.3857  LR: 0.00001309  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 59s) Loss: 0.0076(0.0076) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 57s) Loss: 0.0029(0.0124) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0031(0.0143) \n",
            "EVAL: [238/239] Elapsed 1m 38s (remain 0m 0s) Loss: 0.0078(0.0132) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - avg_train_loss: 0.0115  avg_val_loss: 0.0132  time: 635s\n",
            "Epoch 2 - Score: 0.8526\n",
            "Epoch 2 - Save Best Score: 0.8526 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [3][0/953] Elapsed 0m 1s (remain 16m 58s) Loss: 0.0115(0.0115) Grad: 12356.6875  LR: 0.00001309  \n",
            "Epoch: [3][100/953] Elapsed 0m 57s (remain 8m 1s) Loss: 0.0070(0.0096) Grad: 11055.3555  LR: 0.00001245  \n",
            "Epoch: [3][200/953] Elapsed 1m 53s (remain 7m 3s) Loss: 0.0055(0.0101) Grad: 16892.2070  LR: 0.00001181  \n",
            "Epoch: [3][300/953] Elapsed 2m 49s (remain 6m 6s) Loss: 0.0101(0.0099) Grad: 11008.9072  LR: 0.00001116  \n",
            "Epoch: [3][400/953] Elapsed 3m 45s (remain 5m 11s) Loss: 0.0064(0.0098) Grad: 18427.7637  LR: 0.00001050  \n",
            "Epoch: [3][500/953] Elapsed 4m 42s (remain 4m 14s) Loss: 0.0183(0.0100) Grad: 34408.0469  LR: 0.00000984  \n",
            "Epoch: [3][600/953] Elapsed 5m 38s (remain 3m 18s) Loss: 0.0141(0.0102) Grad: 20380.5625  LR: 0.00000918  \n",
            "Epoch: [3][700/953] Elapsed 6m 35s (remain 2m 22s) Loss: 0.0069(0.0100) Grad: 11135.4795  LR: 0.00000853  \n",
            "Epoch: [3][800/953] Elapsed 7m 31s (remain 1m 25s) Loss: 0.0142(0.0102) Grad: 21890.0293  LR: 0.00000788  \n",
            "Epoch: [3][900/953] Elapsed 8m 27s (remain 0m 29s) Loss: 0.0029(0.0101) Grad: 4382.1045  LR: 0.00000724  \n",
            "Epoch: [3][952/953] Elapsed 8m 56s (remain 0m 0s) Loss: 0.0045(0.0102) Grad: 7667.5923  LR: 0.00000691  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 48s) Loss: 0.0082(0.0082) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0025(0.0125) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0043(0.0143) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0086(0.0133) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - avg_train_loss: 0.0102  avg_val_loss: 0.0133  time: 638s\n",
            "Epoch 3 - Score: 0.8602\n",
            "Epoch 3 - Save Best Score: 0.8602 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [4][0/953] Elapsed 0m 0s (remain 15m 32s) Loss: 0.0090(0.0090) Grad: 11742.6279  LR: 0.00000691  \n",
            "Epoch: [4][100/953] Elapsed 0m 56s (remain 7m 59s) Loss: 0.0111(0.0093) Grad: 17451.2637  LR: 0.00000629  \n",
            "Epoch: [4][200/953] Elapsed 1m 53s (remain 7m 4s) Loss: 0.0037(0.0095) Grad: 15199.1318  LR: 0.00000568  \n",
            "Epoch: [4][300/953] Elapsed 2m 49s (remain 6m 6s) Loss: 0.0091(0.0093) Grad: 31537.2578  LR: 0.00000510  \n",
            "Epoch: [4][400/953] Elapsed 3m 45s (remain 5m 10s) Loss: 0.0163(0.0095) Grad: 50349.2188  LR: 0.00000454  \n",
            "Epoch: [4][500/953] Elapsed 4m 41s (remain 4m 13s) Loss: 0.0092(0.0093) Grad: 21412.4004  LR: 0.00000400  \n",
            "Epoch: [4][600/953] Elapsed 5m 37s (remain 3m 17s) Loss: 0.0088(0.0091) Grad: 19009.1953  LR: 0.00000348  \n",
            "Epoch: [4][700/953] Elapsed 6m 33s (remain 2m 21s) Loss: 0.0172(0.0093) Grad: 73268.1250  LR: 0.00000300  \n",
            "Epoch: [4][800/953] Elapsed 7m 29s (remain 1m 25s) Loss: 0.0295(0.0094) Grad: 31070.7539  LR: 0.00000254  \n",
            "Epoch: [4][900/953] Elapsed 8m 25s (remain 0m 29s) Loss: 0.0110(0.0093) Grad: 49526.5352  LR: 0.00000212  \n",
            "Epoch: [4][952/953] Elapsed 8m 54s (remain 0m 0s) Loss: 0.0176(0.0093) Grad: 24559.9297  LR: 0.00000191  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 58s) Loss: 0.0068(0.0068) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0023(0.0122) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0035(0.0143) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0087(0.0133) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - avg_train_loss: 0.0093  avg_val_loss: 0.0133  time: 635s\n",
            "Epoch 4 - Score: 0.8610\n",
            "Epoch 4 - Save Best Score: 0.8610 Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [5][0/953] Elapsed 0m 1s (remain 16m 42s) Loss: 0.0058(0.0058) Grad: 8590.7256  LR: 0.00000191  \n",
            "Epoch: [5][100/953] Elapsed 0m 57s (remain 8m 1s) Loss: 0.0033(0.0082) Grad: 4141.9570  LR: 0.00000154  \n",
            "Epoch: [5][200/953] Elapsed 1m 52s (remain 7m 2s) Loss: 0.0027(0.0087) Grad: 9442.6299  LR: 0.00000121  \n",
            "Epoch: [5][300/953] Elapsed 2m 48s (remain 6m 5s) Loss: 0.0134(0.0082) Grad: 19283.7305  LR: 0.00000091  \n",
            "Epoch: [5][400/953] Elapsed 3m 44s (remain 5m 9s) Loss: 0.0026(0.0082) Grad: 11781.5322  LR: 0.00000066  \n",
            "Epoch: [5][500/953] Elapsed 4m 40s (remain 4m 13s) Loss: 0.0133(0.0081) Grad: 43817.0938  LR: 0.00000044  \n",
            "Epoch: [5][600/953] Elapsed 5m 36s (remain 3m 17s) Loss: 0.0030(0.0083) Grad: 8214.8740  LR: 0.00000027  \n",
            "Epoch: [5][700/953] Elapsed 6m 32s (remain 2m 21s) Loss: 0.0044(0.0084) Grad: 10001.9580  LR: 0.00000014  \n",
            "Epoch: [5][800/953] Elapsed 7m 28s (remain 1m 25s) Loss: 0.0015(0.0085) Grad: 5671.8335  LR: 0.00000005  \n",
            "Epoch: [5][900/953] Elapsed 8m 24s (remain 0m 29s) Loss: 0.0066(0.0086) Grad: 17948.6270  LR: 0.00000001  \n",
            "Epoch: [5][952/953] Elapsed 8m 53s (remain 0m 0s) Loss: 0.0116(0.0087) Grad: 17124.7773  LR: 0.00000000  \n",
            "EVAL: [0/239] Elapsed 0m 0s (remain 2m 46s) Loss: 0.0069(0.0069) \n",
            "EVAL: [100/239] Elapsed 0m 41s (remain 0m 56s) Loss: 0.0022(0.0126) \n",
            "EVAL: [200/239] Elapsed 1m 22s (remain 0m 15s) Loss: 0.0031(0.0147) \n",
            "EVAL: [238/239] Elapsed 1m 37s (remain 0m 0s) Loss: 0.0088(0.0137) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - avg_train_loss: 0.0087  avg_val_loss: 0.0137  time: 634s\n",
            "Epoch 5 - Score: 0.8608\n",
            "========== fold: 4 result ==========\n",
            "Score: 0.8610\n",
            "========== CV ==========\n",
            "Score: 0.8629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/project.zip /content/project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SPXfHfCEzIh",
        "outputId": "557c9969-1327-426a-fe4e-cf571b7722b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/project/ (stored 0%)\n",
            "  adding: content/project/input/ (stored 0%)\n",
            "  adding: content/project/input/nbme-score-clinical-patient-notes/ (stored 0%)\n",
            "  adding: content/project/input/nbme-score-clinical-patient-notes/features.csv (deflated 52%)\n",
            "  adding: content/project/input/nbme-score-clinical-patient-notes/test.csv (deflated 55%)\n",
            "  adding: content/project/input/nbme-score-clinical-patient-notes/patient_notes.csv (deflated 72%)\n",
            "  adding: content/project/input/nbme-score-clinical-patient-notes/sample_submission.csv (deflated 34%)\n",
            "  adding: content/project/input/nbme-score-clinical-patient-notes/train.csv (deflated 74%)\n",
            "  adding: content/project/input/deberta v2_3 fast tokenizer.zip (stored 0%)\n",
            "  adding: content/project/input/nbme-score-clinical-patient-notes.zip (stored 0%)\n",
            "  adding: content/project/input/deberta-v2-3-fast-tokenizer/ (stored 0%)\n",
            "  adding: content/project/input/deberta-v2-3-fast-tokenizer/transformers__init__.py (deflated 86%)\n",
            "  adding: content/project/input/deberta-v2-3-fast-tokenizer/convert_slow_tokenizer.py (deflated 86%)\n",
            "  adding: content/project/input/deberta-v2-3-fast-tokenizer/tokenization_deberta_v2_fast.py (deflated 70%)\n",
            "  adding: content/project/input/deberta-v2-3-fast-tokenizer/deberta__init__.py (deflated 68%)\n",
            "  adding: content/project/input/deberta-v2-3-fast-tokenizer/tokenization_auto.py (deflated 78%)\n",
            "  adding: content/project/input/deberta-v2-3-fast-tokenizer/tokenization_deberta_v2.py (deflated 74%)\n",
            "  adding: content/project/output/ (stored 0%)\n",
            "  adding: content/project/output/microsoft-deberta-v3-base_fold3_best.pth (deflated 23%)\n",
            "  adding: content/project/output/oof_df.pkl (deflated 51%)\n",
            "  adding: content/project/output/microsoft-deberta-v3-base_fold1_best.pth (deflated 23%)\n",
            "  adding: content/project/output/config.pth (deflated 49%)\n",
            "  adding: content/project/output/train.log (deflated 84%)\n",
            "  adding: content/project/output/microsoft-deberta-v3-base_fold0_best.pth"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomModel(CFG, config_path=None, pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "LarXcX8MFsqi",
        "outputId": "f458251d-6723-4549-bd87-e4587698bf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5846bec84b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'CustomModel' is not defined"
          ]
        }
      ]
    }
  ]
}